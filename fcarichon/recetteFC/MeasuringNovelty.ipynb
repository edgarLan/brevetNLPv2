{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "12595836-c97f-41b7-8caa-a3fe1f2c242b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "from collections import Counter\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "import ast\n",
    "\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from math import log\n",
    "import heapq\n",
    "\n",
    "from nltk.collocations import BigramCollocationFinder, BigramAssocMeasures\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from collections import OrderedDict\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bceaf360-3b9f-40fb-a50d-2648823241b1",
   "metadata": {},
   "source": [
    "### Fichier qui créé mes inputs (Proba dist for all, for each doc, and for new ones, and PMI calculations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1edc696-612b-4a8b-90fa-0fd3f3d0bd4d",
   "metadata": {},
   "source": [
    "Si j'ai des textes, ça doit me ressortir des vecteurs de distributions pour mes documents KB, EB, et pour mes nouveaux et les combinaisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2dcada-0b12-40f3-acbd-e438ab1d3e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pmi(input_, w_size=3):\n",
    "    \"\"\" Input : list of ORDERED feature variables (words for example) -- if feature order does not matter set window_size to inf. \"\"\"\n",
    "    bigram_measures = BigramAssocMeasures()\n",
    "    finder = BigramCollocationFinder.from_words(input_, window_size= w_size)\n",
    "    return finder.score_ngrams(bigram_measures.pmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "9862314f-f5c8-4ac1-ba24-0bb67ad472eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def docs_distribution(text_corpus):\n",
    "    \"\"\"Input : Cleaned text corpus\n",
    "       Output : Probability distribution for each document in corpus and for the all corpus\n",
    "    \"\"\"\n",
    "    Count_KB = vectorizer.fit_transform(text_corpus)\n",
    "    Count_matrix = Count_KB.toarray()\n",
    "\n",
    "    #Getting the term distribution for all documents\n",
    "    Prob_KB_matrix = Count_matrix/Count_matrix.sum(axis=1, keepdims=True)\n",
    "\n",
    "    #Getting the overall term distribution in the all KB -- should be a zipfian law\n",
    "    Count_overall = Count_matrix.sum(axis=0)\n",
    "    Corpus_dist = Count_overall / Count_overall.sum()\n",
    "\n",
    "    return Corpus_dist, Prob_KB_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4e4f6e-d12a-4d68-86c0-d5e1a201ddab",
   "metadata": {},
   "source": [
    "## Pour chaque recette on compute la KB et la EB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254b433d-4b8f-477f-82ad-ab05d1ec15b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for recette in recipe_corpus:\n",
    "\n",
    "    #Getting texts of the KB\n",
    "    ## Revoir code pour obtenir tes recettes en fonction de tes JSON\n",
    "    KB_recettes = []\n",
    "    \n",
    "    #Constituting KB : \n",
    "    KB_dist, KB_matrix = docs_distribution(KB_recettes)\n",
    "    \n",
    "    KB_texts = ' '.join(KB_recettes)\n",
    "    EB_PMI = pmi(KB_texts)\n",
    "\n",
    "    ### Getting the variations for that KB/EB\n",
    "    for variation in variations:\n",
    "\n",
    "        KB_updated = KB_recettes + [variation]\n",
    "        NewKB_dist, KB_temp = docs_distribution(KB_updated)\n",
    "        variation_dist = KB_temp[-1]\n",
    "\n",
    "        KB_textsnew = ' '.join(KB_updated)\n",
    "        EB_New = pmi(KB_textsnew)\n",
    "        \n",
    "        #### Estimating scores\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

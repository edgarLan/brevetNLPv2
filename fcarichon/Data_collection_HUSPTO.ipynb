{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fd59377-2353-4eb5-b4e9-f5432b466156",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import json\n",
    "import collections\n",
    "import re\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "773696c9-f5b2-4633-9c30-e48d632584b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290832"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#List of file to collect\n",
    "mypath = \"C:/Users/edgar/OneDrive/Bureau/Ecole/HEC/A24/BrevetNLP/data/2009/\" #'data/2009/2009/'\n",
    "file_names = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "len(file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45cda745-5519-4a9c-8e8e-5493e39666c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Year 2015 also because we analyse 2016 and 2015 for 2014\n",
    "expect_classes_G06F_2014, expect_classes_H01L_2014, expect_classes_A61B_2014 = [], [], []\n",
    "with open(r'data/expectation_space/2014_G06F_expectation_IPC_class.txt', 'r') as fp:\n",
    "    for line in fp:\n",
    "        x = line[:-1]\n",
    "        expect_classes_G06F_2014.append(x)\n",
    "\n",
    "with open(r'data/expectation_space/2014_H01L_expectation_IPC_class.txt', 'r') as fp:\n",
    "    for line in fp:\n",
    "        x = line[:-1]\n",
    "        expect_classes_H01L_2014.append(x)\n",
    "        \n",
    "with open(r'data/expectation_space/2014_A61B_expectation_IPC_class.txt', 'r') as fp:\n",
    "    for line in fp:\n",
    "        x = line[:-1]\n",
    "        expect_classes_A61B_2014.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c9ae09c-d9ba-424b-8d62-22c38a0441a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 290832/290832 [20:26<00:00, 237.03it/s]\n"
     ]
    }
   ],
   "source": [
    "#Getting files in this XXXX year related to main classes and other classes\n",
    "knowledge_space_G06F = []\n",
    "knowledge_space_H01L = []\n",
    "knowledge_space_A61B = []\n",
    "\n",
    "expectation_space_G06F_2014 = []\n",
    "expectation_space_H01L_2014 = []\n",
    "expectation_space_A61B_2014 = []\n",
    "\n",
    "for i in tqdm(range(len(file_names))):\n",
    "    patent_path = mypath + file_names[i]\n",
    "    with open(patent_path) as f:\n",
    "        d = json.load(f)\n",
    "        f.close()\n",
    "    \n",
    "    class_mainIPC = d['main_ipcr_label']\n",
    "    class_main = class_mainIPC[0:4]\n",
    "    #We are collecting all documents related to the main class - we distinguish them later by date\n",
    "    if class_main == 'G06F':\n",
    "        knowledge_space_G06F.append(file_names[i])\n",
    "    if class_main == 'H01L':\n",
    "        knowledge_space_H01L.append(file_names[i])\n",
    "    if class_main == 'A61B':\n",
    "        knowledge_space_A61B.append(file_names[i])\n",
    "    \n",
    "    #For the expectations states - we have one for each year since the class are not similar\n",
    "    #2014\n",
    "    if class_mainIPC in expect_classes_G06F_2014:\n",
    "        expectation_space_G06F_2014.append(file_names[i])\n",
    "    if class_mainIPC in expect_classes_H01L_2014:\n",
    "        expectation_space_H01L_2014.append(file_names[i])\n",
    "    if class_mainIPC in expect_classes_A61B_2014:\n",
    "        expectation_space_A61B_2014.append(file_names[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7736a5e5-132d-4601-b366-6081606407e2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 7754/7754 [00:26<00:00, 287.54it/s]\n"
     ]
    }
   ],
   "source": [
    "#Saving knowledge space per year in csv\n",
    "patent_number, decisions, titles, backgrounds, claims = [], [], [], [], []\n",
    "current_date = 20140101\n",
    "for i in tqdm(range(len(knowledge_space_A61B))):\n",
    "    patent_path = mypath + knowledge_space_A61B[i]\n",
    "    with open(patent_path) as f:\n",
    "        d = json.load(f)\n",
    "        f.close()\n",
    "    #Not taking patnts that are not published yet\n",
    "    if int(d['date_published']) < current_date:\n",
    "        \n",
    "        #Creating the lists for the other information\n",
    "        patent_number.append(d['application_number'])\n",
    "        titles.append(d['title'])\n",
    "        backgrounds.append(d['background'])\n",
    "        claims.append(d['claims'])\n",
    "        decisions.append(d['decision'])\n",
    "    else:\n",
    "        #If the date is superior to 2016, we still take accepted or rejected into account\n",
    "        if d['decision'] == 'ACCEPTED' or d['decision'] == 'REJECTED':\n",
    "            #Creating the lists for the other information\n",
    "            patent_number.append(d['application_number'])\n",
    "            titles.append(d['title'])\n",
    "            backgrounds.append(d['background'])\n",
    "            claims.append(d['claims'])\n",
    "            decisions.append(d['decision'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e11f9744-d0d2-4101-9ffb-23aa57a632a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7754\n"
     ]
    }
   ],
   "source": [
    "df_known = pd.DataFrame({'application_number': patent_number, 'title': titles, 'background': backgrounds, 'claims':claims, 'decision': decisions})\n",
    "print(len(df_known))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dada369e-248f-4ccf-a4f4-c01e95040a5e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1642478469.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    ('data/knowledge_space/20142009_A61B_knowledge_space_raw.csv', index=False)\u001b[0m\n\u001b[1;37m                                                                        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "df_known.to_csv('data/knowledge_space/20142009_A61B_knowledge_space_raw.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9c965138-322e-4c54-8118-1e5a4b35db34",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 46575/46575 [01:34<00:00, 492.89it/s]\n"
     ]
    }
   ],
   "source": [
    "#Saving expectations space per year in csv\n",
    "patent_number, decisions, titles, backgrounds, claims = [], [], [], [], []\n",
    "current_date = 20140101\n",
    "for i in tqdm(range(len(expectation_space_A61B_2014))):\n",
    "    patent_path = mypath + expectation_space_A61B_2014[i]\n",
    "    with open(patent_path) as f:\n",
    "        d = json.load(f)\n",
    "        f.close()\n",
    "    \n",
    "    #Not taking patnts that are not published yet\n",
    "    if int(d['date_published']) < current_date:\n",
    "        \n",
    "        #Creating the lists for the other information\n",
    "        patent_number.append(d['application_number'])\n",
    "        titles.append(d['title'])\n",
    "        backgrounds.append(d['background'])\n",
    "        claims.append(d['claims'])\n",
    "        decisions.append(d['decision'])\n",
    "    else:\n",
    "        #If the date is superior to 2016, we still take accepted or rejected into account\n",
    "        if d['decision'] == 'ACCEPTED' or d['decision'] == 'REJECTED':\n",
    "            #Creating the lists for the other information\n",
    "            patent_number.append(d['application_number'])\n",
    "            titles.append(d['title'])\n",
    "            backgrounds.append(d['background'])\n",
    "            claims.append(d['claims'])\n",
    "            decisions.append(d['decision'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "86dc64c9-f426-4691-b318-5d13ed93a32e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46573\n"
     ]
    }
   ],
   "source": [
    "df_expect = pd.DataFrame({'application_number': patent_number, 'title': titles, 'background': backgrounds, 'claims':claims, 'decision': decisions})\n",
    "print(len(df_expect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f096a17c-acca-491f-ae54-7a3b3f13e3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expect.to_csv('data/expectation_space/20142009_A61B_expectation_space_raw.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef0d779-d801-46cd-9145-d1fec131db34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

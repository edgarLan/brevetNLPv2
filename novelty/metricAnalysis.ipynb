{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importation données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import ttest_ind\n",
    "import numpy as np\n",
    "path = \"C:/Users/edgar/OneDrive/Bureau/Ecole/HEC/A24/BrevetNLP/exemple données/metrics/2012_H01L_claims_vs_claims_background_Metrics.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/Users/edgar/OneDrive/Bureau/Ecole/HEC/A24/BrevetNLP/exemple données/metrics/2012_H01L_claims_vs_claims_background_Metrics.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\edgar\\OneDrive\\Bureau\\Ecole\\HEC\\A24\\BrevetNLP\\.conda\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\edgar\\OneDrive\\Bureau\\Ecole\\HEC\\A24\\BrevetNLP\\.conda\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\edgar\\OneDrive\\Bureau\\Ecole\\HEC\\A24\\BrevetNLP\\.conda\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\edgar\\OneDrive\\Bureau\\Ecole\\HEC\\A24\\BrevetNLP\\.conda\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\edgar\\OneDrive\\Bureau\\Ecole\\HEC\\A24\\BrevetNLP\\.conda\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/edgar/OneDrive/Bureau/Ecole/HEC/A24/BrevetNLP/exemple données/metrics/2012_H01L_claims_vs_claims_background_Metrics.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>application_number</th>\n",
       "      <th>label</th>\n",
       "      <th>new_ratio</th>\n",
       "      <th>new_bin</th>\n",
       "      <th>uniq_ratio</th>\n",
       "      <th>uniq_bin</th>\n",
       "      <th>diff_ratio</th>\n",
       "      <th>diff_bin</th>\n",
       "      <th>neighboroud_distance</th>\n",
       "      <th>surpDiv_ratio</th>\n",
       "      <th>surpDiv_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13482313</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0</td>\n",
       "      <td>0.492441</td>\n",
       "      <td>0</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0</td>\n",
       "      <td>0.379939</td>\n",
       "      <td>0.116744</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13674006</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>0</td>\n",
       "      <td>0.519067</td>\n",
       "      <td>0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1</td>\n",
       "      <td>0.379939</td>\n",
       "      <td>0.170545</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13500084</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>0</td>\n",
       "      <td>0.541795</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0</td>\n",
       "      <td>0.379939</td>\n",
       "      <td>0.096064</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13344492</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0</td>\n",
       "      <td>0.494423</td>\n",
       "      <td>0</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0</td>\n",
       "      <td>0.379939</td>\n",
       "      <td>0.123130</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13609643</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>0</td>\n",
       "      <td>0.476105</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.379939</td>\n",
       "      <td>0.133284</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19193</th>\n",
       "      <td>13512955</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>0</td>\n",
       "      <td>0.508650</td>\n",
       "      <td>0</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1</td>\n",
       "      <td>0.379939</td>\n",
       "      <td>0.167717</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19194</th>\n",
       "      <td>13607276</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000320</td>\n",
       "      <td>0</td>\n",
       "      <td>0.493389</td>\n",
       "      <td>0</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1</td>\n",
       "      <td>0.379939</td>\n",
       "      <td>0.149307</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19195</th>\n",
       "      <td>13380703</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>0</td>\n",
       "      <td>0.581730</td>\n",
       "      <td>1</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1</td>\n",
       "      <td>0.379939</td>\n",
       "      <td>0.189979</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19196</th>\n",
       "      <td>13680773</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>0</td>\n",
       "      <td>0.550384</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.379939</td>\n",
       "      <td>0.142447</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19197</th>\n",
       "      <td>13607688</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>0</td>\n",
       "      <td>0.519458</td>\n",
       "      <td>0</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1</td>\n",
       "      <td>0.379939</td>\n",
       "      <td>0.149140</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19198 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       application_number  label  new_ratio  new_bin  uniq_ratio  uniq_bin  \\\n",
       "0                13482313      0   0.000168        0    0.492441         0   \n",
       "1                13674006      1   0.000341        0    0.519067         0   \n",
       "2                13500084      0   0.000242        0    0.541795         1   \n",
       "3                13344492      1   0.000229        0    0.494423         0   \n",
       "4                13609643      1   0.000246        0    0.476105         0   \n",
       "...                   ...    ...        ...      ...         ...       ...   \n",
       "19193            13512955      0   0.000238        0    0.508650         0   \n",
       "19194            13607276      1   0.000320        0    0.493389         0   \n",
       "19195            13380703      0   0.000371        0    0.581730         1   \n",
       "19196            13680773      1   0.000238        0    0.550384         1   \n",
       "19197            13607688      0   0.000272        0    0.519458         0   \n",
       "\n",
       "       diff_ratio  diff_bin  neighboroud_distance  surpDiv_ratio  surpDiv_bin  \n",
       "0            0.46         0              0.379939       0.116744            1  \n",
       "1            0.95         1              0.379939       0.170545            1  \n",
       "2            0.76         0              0.379939       0.096064            1  \n",
       "3            0.60         0              0.379939       0.123130            1  \n",
       "4            0.00         0              0.379939       0.133284            1  \n",
       "...           ...       ...                   ...            ...          ...  \n",
       "19193        0.98         1              0.379939       0.167717            1  \n",
       "19194        0.98         1              0.379939       0.149307            1  \n",
       "19195        0.99         1              0.379939       0.189979            1  \n",
       "19196        1.00         1              0.379939       0.142447            1  \n",
       "19197        0.96         1              0.379939       0.149140            1  \n",
       "\n",
       "[19198 rows x 11 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corrélations labels et ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "def correl_labelScores(df):\n",
    "    # Select columns ending with 'ratio'\n",
    "    ratio_columns = [col for col in df.columns if col.endswith(\"ratio\")]\n",
    "\n",
    "    # Compute Pearson and Spearman correlations\n",
    "    pearson_corr = df[[\"label\"] + ratio_columns].corr(method=\"pearson\")[\"label\"].drop(\"label\")\n",
    "    spearman_corr = df[[\"label\"] + ratio_columns].corr(method=\"spearman\")[\"label\"].drop(\"label\")\n",
    "\n",
    "    # Calculate p-values\n",
    "    pearson_pvals = {col: pearsonr(df[\"label\"], df[col])[1] for col in ratio_columns}\n",
    "    spearman_pvals = {col: spearmanr(df[\"label\"], df[col])[1] for col in ratio_columns}\n",
    "\n",
    "    # Formatting the result as a DataFrame\n",
    "    results = pd.DataFrame({\n",
    "        0: [\"Correlation label and metric\", \"pearson correlation (p-value)\", \"spearman correlation (p-value)\"],\n",
    "        1: [\"newness\", f\"{pearson_corr['new_ratio']:.3f} ({pearson_pvals['new_ratio']:.3f})\", f\"{spearman_corr['new_ratio']:.3f} ({spearman_pvals['new_ratio']:.3f})\"],\n",
    "        2: [\"uniqueness\", f\"{pearson_corr['uniq_ratio']:.3f} ({pearson_pvals['uniq_ratio']:.3f})\", f\"{spearman_corr['uniq_ratio']:.3f} ({spearman_pvals['uniq_ratio']:.3f})\"],\n",
    "        3: [\"difference\", f\"{pearson_corr['diff_ratio']:.3f} ({pearson_pvals['diff_ratio']:.3f})\", f\"{spearman_corr['diff_ratio']:.3f} ({spearman_pvals['diff_ratio']:.3f})\"],\n",
    "        4: [\"surprise divergence\", f\"{pearson_corr['surpDiv_ratio']:.3f} ({pearson_pvals['surpDiv_ratio']:.3f})\", f\"{spearman_corr['surpDiv_ratio']:.3f} ({spearman_pvals['surpDiv_ratio']:.3f})\"]\n",
    "    })\n",
    "\n",
    "    # Return final DataFrame\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "def ttest_metric(df):\n",
    "    ratio_columns = [col for col in df.columns if col.endswith(\"ratio\")]\n",
    "    # Perform t-test for each ratio column\n",
    "    t_test_results = {}\n",
    "    for col in ratio_columns:\n",
    "        group_0 = df[df[\"label\"] == 0][col]\n",
    "        group_1 = df[df[\"label\"] == 1][col]\n",
    "\n",
    "        # Perform t-test\n",
    "        t_stat, p_value = ttest_ind(group_1, group_0, equal_var=False)  # Welch's t-test\n",
    "        t_test_results[col] = {\"t_stat\": t_stat, \"p_value\": p_value}\n",
    "\n",
    "    # Convert results to DataFrame for better visualization\n",
    "    t_test_df = pd.DataFrame.from_dict(t_test_results, orient=\"index\")\n",
    "    \n",
    "    # Insert the ratio names as the first column\n",
    "    t_test_df.insert(0, 'Metric', t_test_df.index)\n",
    "    \n",
    "    # Reset the index and columns to 0, 1, 2,...\n",
    "    t_test_df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # Set the first row to be blank and add 't_stat' and 'p_value' in the second row\n",
    "    t_test_df.columns = [0,1,2]  # Rename the columns\n",
    "    t_test_df.loc[-1] =  [\"\", 't_stat', 'p_value'] # Add a blank first row\n",
    "    t_test_df.index = t_test_df.index + 1  # Shift index to make room for the new row\n",
    "    t_test_df = t_test_df.sort_index()  # Re-sort the DataFrame by the index\n",
    "    \n",
    "    return t_test_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intercorrélations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kendalltau\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def KTcorrel_metrics(df):\n",
    "    # Select only ratio columns\n",
    "    ratio_columns = [col for col in df.columns if col.endswith(\"_ratio\")]\n",
    "\n",
    "    # Initialize an empty DataFrame with \"-\" for the upper triangle\n",
    "    kendall_matrix = pd.DataFrame(np.full((len(ratio_columns), len(ratio_columns)), \"-\", dtype=\"object\"))\n",
    "\n",
    "    # Compute Kendall's Tau for the lower triangular part and diagonal\n",
    "    for i, col1 in enumerate(ratio_columns):\n",
    "        for j, col2 in enumerate(ratio_columns):\n",
    "            if i >= j:  # Lower triangular and diagonal part\n",
    "                tau, p_value = kendalltau(df[col1], df[col2])\n",
    "                # Format the result as 'tau_value (p_value)'\n",
    "                kendall_matrix.iloc[i, j] = f\"{tau:.3f} ({p_value:.3f})\"\n",
    "\n",
    "    # Insert the ratio column names as the first column\n",
    "    kendall_matrix.insert(0, \"Metrics\", ratio_columns)\n",
    "\n",
    "    # Insert a blank row as the first row (0, new_ratio, uniq_ratio, ...)\n",
    "    kendall_matrix.loc[-1] = [\"\"] + ratio_columns  # Add a blank row\n",
    "    kendall_matrix.index = kendall_matrix.index + 1  # Shift the index\n",
    "    kendall_matrix = kendall_matrix.sort_index()  # Sort the DataFrame to fix the index order\n",
    "\n",
    "    # Set column numbers starting from 0, including the first column with the Metrics\n",
    "    kendall_matrix.columns = [0] + list(range(1, len(ratio_columns) + 1))  # First column = 0\n",
    "\n",
    "    return kendall_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rbo  # Assuming rbo is already installed\n",
    "\n",
    "def rbo_metrics(df, p):\n",
    "    # Select only ratio columns\n",
    "    ratio_columns = [col for col in df.columns if col.endswith(\"_ratio\")]\n",
    "\n",
    "    # Initialize an empty DataFrame for the RBO matrix\n",
    "    rbo_matrix = pd.DataFrame(np.ones((len(ratio_columns), len(ratio_columns))), columns=ratio_columns)\n",
    "\n",
    "    # Ensure the DataFrame can hold string values (object dtype)\n",
    "    rbo_matrix = rbo_matrix.astype(\"object\")\n",
    "\n",
    "    # Compute RBO for all pairs of ratio columns\n",
    "    for col1, col2 in combinations(ratio_columns, 2):\n",
    "        # Rank the values (from high to low)\n",
    "        rank1 = df[col1].sort_values(ascending=False).index.tolist()\n",
    "        rank2 = df[col2].sort_values(ascending=False).index.tolist()\n",
    "        \n",
    "        # Compute RBO (with given p value)\n",
    "        rbo_score = rbo.RankingSimilarity(rank1, rank2).rbo(p=p)\n",
    "        \n",
    "        # Format the result\n",
    "        rbo_matrix.loc[ratio_columns.index(col1), col2] = f\"{rbo_score:.3f}\"\n",
    "        rbo_matrix.loc[ratio_columns.index(col2), col1] = f\"{rbo_score:.3f}\"\n",
    "\n",
    "    # Fill the upper triangle with \"_\"\n",
    "    for i in range(len(ratio_columns)):\n",
    "        for j in range(i+1, len(ratio_columns)):\n",
    "            rbo_matrix.iloc[i, j] = \"-\"\n",
    "\n",
    "    # Insert the ratio column names as the first column\n",
    "    rbo_matrix.insert(0, \"Metrics\", ratio_columns)\n",
    "\n",
    "    # Adjust column names to start from 0\n",
    "    # rbo_matrix.columns = range(len(rbo_matrix.columns))\n",
    "\n",
    "     # Insert a blank row as the first row (0, new_ratio, uniq_ratio, ...)\n",
    "    rbo_matrix.loc[-1] = [\"\"] + ratio_columns  # Add a blank row\n",
    "    rbo_matrix.index = rbo_matrix.index + 1  # Shift the index\n",
    "    rbo_matrix = rbo_matrix.sort_index()  # Sort the DataFrame to fix the index order\n",
    "\n",
    "    # Set column numbers starting from 0, including the first column with the Metrics\n",
    "    rbo_matrix.columns = [0] + list(range(1, len(ratio_columns) + 1))  # First column = 0\n",
    "\n",
    "    return rbo_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>new_ratio</td>\n",
       "      <td>uniq_ratio</td>\n",
       "      <td>diff_ratio</td>\n",
       "      <td>surpDiv_ratio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>new_ratio</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>uniq_ratio</td>\n",
       "      <td>0.052</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>diff_ratio</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>surpDiv_ratio</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0          1           2           3              4\n",
       "0                 new_ratio  uniq_ratio  diff_ratio  surpDiv_ratio\n",
       "1      new_ratio        1.0           -           -              -\n",
       "2     uniq_ratio      0.052         1.0           -              -\n",
       "3     diff_ratio      0.008       0.000         1.0              -\n",
       "4  surpDiv_ratio      0.000       0.006       0.000            1.0"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rbo_metrics(df, 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def rL_full(df):\n",
    "    # Define dependent and independent variables\n",
    "    X = df[['new_ratio', 'uniq_ratio', 'diff_ratio', 'surpDiv_ratio']]  # 4 ratios\n",
    "    X = sm.add_constant(X)  # Add a constant for the intercept\n",
    "    y = df['label']\n",
    "\n",
    "    # Fit the logistic regression model\n",
    "    model1 = sm.Logit(y, X)\n",
    "    result1 = model1.fit()\n",
    "\n",
    "    # Extract Coefficients, Standard Errors, P-values\n",
    "    coefficients_model1 = result1.params\n",
    "    std_err_model1 = result1.bse\n",
    "    pvalues_model1 = result1.pvalues\n",
    "\n",
    "    # Extract Pseudo R-squared and Likelihood Ratio (LLR) p-value\n",
    "    r2_model1 = result1.prsquared  # McFadden's R-squared\n",
    "    llr_p_value = result1.llr_pvalue\n",
    "\n",
    "    # Prepare a DataFrame for the output\n",
    "    output_df = pd.DataFrame({\n",
    "        0: [\"\", 'const', 'Newness', 'Difference', 'Uniqueness', 'Surprise', 'Pseudo R-square', 'LLR p-value'],\n",
    "        1: [\n",
    "            'coef',\n",
    "            round(coefficients_model1.get('const', np.nan), 3),\n",
    "            round(coefficients_model1.get('new_ratio', np.nan), 3),\n",
    "            round(coefficients_model1.get('diff_ratio', np.nan), 3),\n",
    "            round(coefficients_model1.get('uniq_ratio', np.nan), 3),\n",
    "            round(coefficients_model1.get('surpDiv_ratio', np.nan), 3),\n",
    "            round(r2_model1, 3),  # Pseudo R-square\n",
    "            round(llr_p_value, 3)  # LLR p-value\n",
    "        ],\n",
    "        2: [\n",
    "            'std err',\n",
    "            round(std_err_model1.get('const', np.nan), 3),\n",
    "            round(std_err_model1.get('new_ratio', np.nan), 3),\n",
    "            round(std_err_model1.get('diff_ratio', np.nan), 3),\n",
    "            round(std_err_model1.get('uniq_ratio', np.nan), 3),\n",
    "            round(std_err_model1.get('surpDiv_ratio', np.nan), 3),\n",
    "            np.nan,  # No std err for Pseudo R-square\n",
    "            np.nan   # No std err for LLR p-value\n",
    "        ],\n",
    "        3: [\n",
    "            'P>|t|',\n",
    "            round(pvalues_model1.get('const', np.nan), 3),\n",
    "            round(pvalues_model1.get('new_ratio', np.nan), 3),\n",
    "            round(pvalues_model1.get('diff_ratio', np.nan), 3),\n",
    "            round(pvalues_model1.get('uniq_ratio', np.nan), 3),\n",
    "            round(pvalues_model1.get('surpDiv_ratio', np.nan), 3),\n",
    "            np.nan,  # No p-value for Pseudo R-square\n",
    "            np.nan   # No p-value for LLR p-value\n",
    "        ]\n",
    "    })\n",
    "\n",
    "\n",
    "    return output_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.550152\n",
      "         Iterations 19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>coef</td>\n",
       "      <td>std err</td>\n",
       "      <td>P&gt;|t|</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>const</td>\n",
       "      <td>2.131</td>\n",
       "      <td>0.236</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Newness</td>\n",
       "      <td>89.98</td>\n",
       "      <td>338.084</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Difference</td>\n",
       "      <td>-0.254</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Uniqueness</td>\n",
       "      <td>-3.179</td>\n",
       "      <td>0.511</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Surprise</td>\n",
       "      <td>5.063</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Pseudo R-square</td>\n",
       "      <td>0.012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LLR p-value</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0      1        2      3\n",
       "0                    coef  std err  P>|t|\n",
       "1            const  2.131    0.236    0.0\n",
       "2          Newness  89.98  338.084   0.79\n",
       "3       Difference -0.254     0.05    0.0\n",
       "4       Uniqueness -3.179    0.511    0.0\n",
       "5         Surprise  5.063     0.64    0.0\n",
       "6  Pseudo R-square  0.012      NaN    NaN\n",
       "7      LLR p-value    0.0      NaN    NaN"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rL_full(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def rL_metricSeparate(df):\n",
    "    # Define dependent variable\n",
    "    y = df['label']\n",
    "\n",
    "    # List of metrics (independent variables)\n",
    "    metrics = ['new_ratio', 'uniq_ratio', 'diff_ratio', 'surpDiv_ratio']\n",
    "\n",
    "    # Create an empty list to store DataFrames\n",
    "    df_list = []\n",
    "\n",
    "    # Loop through each metric and refit the model\n",
    "    for metric in metrics:\n",
    "        # Define independent variable (X) as the metric\n",
    "        X = df[[metric]]\n",
    "        X = sm.add_constant(X)  # Add a constant for the intercept\n",
    "\n",
    "        # Fit the logistic regression model\n",
    "        model = sm.Logit(y, X)\n",
    "        result = model.fit()\n",
    "\n",
    "        # Extract coefficients, standard errors, p-values\n",
    "        coef_const = round(result.params['const'], 3)\n",
    "        coef_metric = round(result.params[metric], 3)\n",
    "        std_err_const = round(result.bse['const'], 3)\n",
    "        std_err_metric = round(result.bse[metric], 3)\n",
    "        p_value_const = round(result.pvalues['const'], 3)\n",
    "        p_value_metric = round(result.pvalues[metric], 3)\n",
    "\n",
    "        # Extract Pseudo R-squared and Likelihood Ratio (LLR) p-value\n",
    "        r2 = round(result.prsquared, 3)\n",
    "        llr_p_value = f\"{result.llr_pvalue:.3E}\"\n",
    "\n",
    "        # Create a DataFrame for this metric\n",
    "        metric_df = pd.DataFrame({\n",
    "            0: ['', 'const', metric, 'Pseudo R-square', 'LLR p-value'],\n",
    "            1: ['coef', coef_const, coef_metric, r2, llr_p_value],\n",
    "            2: ['std err', std_err_const, std_err_metric, \"\", \"\"],\n",
    "            3: ['P>|t|', p_value_const, p_value_metric, \"\", \"\"]\n",
    "        })\n",
    "\n",
    "        # Append DataFrame and a blank row\n",
    "        df_list.append(metric_df)\n",
    "        df_list.append(pd.DataFrame({0: [\"\"], 1: [\"\"], 2: [\"\"], 3: [\"\"]}))  # Blank row\n",
    "\n",
    "    # Concatenate all DataFrames\n",
    "    final_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "    return final_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.555513\n",
      "         Iterations 16\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.552403\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.553181\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.555014\n",
      "         Iterations 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>coef</td>\n",
       "      <td>std err</td>\n",
       "      <td>P&gt;|t|</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>const</td>\n",
       "      <td>1.636</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>new_ratio</td>\n",
       "      <td>-2004.447</td>\n",
       "      <td>277.535</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pseudo R-square</td>\n",
       "      <td>0.002</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LLR p-value</td>\n",
       "      <td>6.054E-13</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>coef</td>\n",
       "      <td>std err</td>\n",
       "      <td>P&gt;|t|</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>const</td>\n",
       "      <td>3.443</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>uniq_ratio</td>\n",
       "      <td>-4.669</td>\n",
       "      <td>0.357</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Pseudo R-square</td>\n",
       "      <td>0.008</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LLR p-value</td>\n",
       "      <td>4.014E-39</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td></td>\n",
       "      <td>coef</td>\n",
       "      <td>std err</td>\n",
       "      <td>P&gt;|t|</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>const</td>\n",
       "      <td>1.391</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>diff_ratio</td>\n",
       "      <td>-0.464</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Pseudo R-square</td>\n",
       "      <td>0.007</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LLR p-value</td>\n",
       "      <td>1.337E-32</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td></td>\n",
       "      <td>coef</td>\n",
       "      <td>std err</td>\n",
       "      <td>P&gt;|t|</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>const</td>\n",
       "      <td>0.382</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>surpDiv_ratio</td>\n",
       "      <td>5.414</td>\n",
       "      <td>0.644</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Pseudo R-square</td>\n",
       "      <td>0.003</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>LLR p-value</td>\n",
       "      <td>3.617E-17</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0          1        2      3\n",
       "0                         coef  std err  P>|t|\n",
       "1             const      1.636    0.073    0.0\n",
       "2         new_ratio  -2004.447  277.535    0.0\n",
       "3   Pseudo R-square      0.002                \n",
       "4       LLR p-value  6.054E-13                \n",
       "5                                             \n",
       "6                         coef  std err  P>|t|\n",
       "7             const      3.443    0.179    0.0\n",
       "8        uniq_ratio     -4.669    0.357    0.0\n",
       "9   Pseudo R-square      0.008                \n",
       "10      LLR p-value  4.014E-39                \n",
       "11                                            \n",
       "12                        coef  std err  P>|t|\n",
       "13            const      1.391    0.029    0.0\n",
       "14       diff_ratio     -0.464    0.039    0.0\n",
       "15  Pseudo R-square      0.007                \n",
       "16      LLR p-value  1.337E-32                \n",
       "17                                            \n",
       "18                        coef  std err  P>|t|\n",
       "19            const      0.382    0.089    0.0\n",
       "20    surpDiv_ratio      5.414    0.644    0.0\n",
       "21  Pseudo R-square      0.003                \n",
       "22      LLR p-value  3.617E-17                \n",
       "23                                            "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rL_metricSeparate(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\edgar\\OneDrive\\Bureau\\Ecole\\HEC\\A24\\BrevetNLP\\.conda\\Lib\\site-packages\\spacy\\util.py:910: UserWarning: [W095] Model 'en_core_web_sm' (3.8.0) was trained with spaCy v3.8.0 and may not be 100% compatible with the current version (3.7.5). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\edgar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "c:\\Users\\edgar\\OneDrive\\Bureau\\Ecole\\HEC\\A24\\BrevetNLP\\.conda\\Lib\\site-packages\\spacy\\util.py:910: UserWarning: [W095] Model 'en_core_web_sm' (3.8.0) was trained with spaCy v3.8.0 and may not be 100% compatible with the current version (3.7.5). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\edgar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'textCleaning' from 'c:\\\\Users\\\\edgar\\\\OneDrive\\\\Bureau\\\\Ecole\\\\HEC\\\\A24\\\\BrevetNLP\\\\PatentNovelty\\\\novelty\\\\textCleaning.py'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import textCleaning\n",
    "importlib.reload(textCleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/edgar/OneDrive/Bureau/Ecole/HEC/A24/BrevetNLP/exemple données/metrics/\"\n",
    "from textCleaning import get_file_names, extract_year_ipc_vs\n",
    "p=0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def merge_dataframes_with_blank_lines(df_list, df_names):\n",
    "    \"\"\"\n",
    "    Merges a list of DataFrames into a single DataFrame with blank rows between them.\n",
    "    Ensures column alignment and fills missing values with blanks instead of NaN.\n",
    "    Adds DataFrame names in the first column of blank rows and avoids an extra blank row.\n",
    "\n",
    "    Parameters:\n",
    "        df_list (list of pd.DataFrame): List of DataFrames to merge.\n",
    "        df_names (list of str): List of names corresponding to the DataFrames in df_list.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A merged DataFrame with blank rows in between and names in the first column.\n",
    "    \"\"\"\n",
    "    # Collect all column names and ensure they are strings\n",
    "    all_columns = set()\n",
    "    for df in df_list:\n",
    "        all_columns.update(map(str, df.columns))  # Convert all column names to strings\n",
    "\n",
    "    # Ensure consistent column order\n",
    "    all_columns = sorted(all_columns, key=str)  # Sort as strings to avoid type errors\n",
    "\n",
    "    # Standardize DataFrames by including all columns\n",
    "    standardized_dfs = [df.rename(columns=str).reindex(columns=all_columns, fill_value=\"\") for df in df_list]\n",
    "\n",
    "    # Create a blank row DataFrame with the correct columns\n",
    "    blank_row = pd.DataFrame([[\"\"] * len(all_columns)], columns=all_columns)\n",
    "\n",
    "    # Create a list to hold the DataFrames with their names\n",
    "    merged_dfs_with_names = []\n",
    "\n",
    "    # Interleave blank rows between DataFrames and add the names in the first column of the blank row\n",
    "    for df, name in zip(standardized_dfs, df_names):\n",
    "        # Create a blank row with the name of the DataFrame in the first column and blanks for others\n",
    "        name_row = pd.DataFrame([[name] + [\"\"] * (len(all_columns)-1)], columns=all_columns)\n",
    "        merged_dfs_with_names.append(name_row)  # Add the name row\n",
    "        merged_dfs_with_names.append(df)  # Add the DataFrame itself\n",
    "        merged_dfs_with_names.append(blank_row)  # Add a blank row after each DataFrame\n",
    "\n",
    "    # Merge all DataFrames, interleaving blank rows between them\n",
    "    merged_df = pd.concat(merged_dfs_with_names, ignore_index=True)\n",
    "\n",
    "    return merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2012_H01L_abstract_summary_vs_abstract_summary_background_Metrics.csv\n",
      "('2012', 'H01L', 'abstract_summary_vs_abstract_summary_background')\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.553340\n",
      "         Iterations 13\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.555767\n",
      "         Iterations 12\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.554124\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.554222\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.556844\n",
      "         Iterations 5\n",
      "2013_H01L_abstract_summary_vs_abstract_summary_background_Metrics.csv\n",
      "('2013', 'H01L', 'abstract_summary_vs_abstract_summary_background')\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.511983\n",
      "         Iterations 16\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.514079\n",
      "         Iterations 11\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.513126\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.513274\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.516102\n",
      "         Iterations 5\n",
      "2014_H01L_abstract_summary_vs_abstract_summary_background_Metrics.csv\n",
      "('2014', 'H01L', 'abstract_summary_vs_abstract_summary_background')\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.497476\n",
      "         Iterations 16\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.500561\n",
      "         Iterations 13\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.498924\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.499075\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.502433\n",
      "         Iterations 5\n",
      "2015_H01L_abstract_summary_vs_abstract_summary_background_Metrics.csv\n",
      "('2015', 'H01L', 'abstract_summary_vs_abstract_summary_background')\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.441399\n",
      "         Iterations 16\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.442253\n",
      "         Iterations 15\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.441502\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.442558\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.443063\n",
      "         Iterations 6\n",
      "2016_H01L_abstract_summary_vs_abstract_summary_background_Metrics.csv\n",
      "('2016', 'H01L', 'abstract_summary_vs_abstract_summary_background')\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.329191\n",
      "         Iterations 25\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.330306\n",
      "         Iterations 20\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.329982\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.329276\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.330459\n",
      "         Iterations 6\n",
      "DataFrames written to C:/Users/edgar/OneDrive/Bureau/Ecole/HEC/A24/BrevetNLP/exemple données/metrics//output.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to output data to Excel\n",
    "def output_to_excel(df_list, sheet_names, output_file):\n",
    "    \"\"\"\n",
    "    Outputs the list of DataFrames to an Excel file, each DataFrame on a separate sheet.\n",
    "\n",
    "    Parameters:\n",
    "        df_list (list of pd.DataFrame): List of DataFrames to output.\n",
    "        sheet_names (list of str): List of sheet names corresponding to each DataFrame.\n",
    "        output_file (str): Path to the output Excel file.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Create a Pandas Excel writer object\n",
    "    with pd.ExcelWriter(output_file, engine='xlsxwriter') as writer:\n",
    "        for df, sheet_name in zip(df_list, sheet_names):\n",
    "            df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "    print(f\"DataFrames written to {output_file}\")\n",
    "\n",
    "# Initialize a list to store DataFrames and their corresponding sheet names\n",
    "df_list = []\n",
    "sheet_names = []\n",
    "\n",
    "# Assuming get_file_names(path) gives a list of filenames\n",
    "for file in get_file_names(path):  # You may adjust the slicing as needed\n",
    "    print(file)\n",
    "    print(extract_year_ipc_vs(file))\n",
    "    df = pd.read_csv(path+file)\n",
    "    \n",
    "    # Call functions to generate DataFrames for each metric\n",
    "    correl = correl_labelScores(df)\n",
    "    kt = KTcorrel_metrics(df)\n",
    "    ttest_df = ttest_metric(df)\n",
    "    rbo_df = rbo_metrics(df, p)\n",
    "    rL = rL_full(df)\n",
    "    rL_ind = rL_metricSeparate(df)\n",
    "    \n",
    "    # Merge DataFrames with blank rows and names\n",
    "    final_df = merge_dataframes_with_blank_lines([correl, kt, ttest_df, rbo_df, rL, rL_ind], ['Corrélation', 'Kendall-Tau', \"t-test\", 'RBO', 'RL (MLE)', 'RL_ind (MLE)'])\n",
    "    \n",
    "    # Extract and join the year information to form the sheet name\n",
    "    sheet_name = ('_'.join(extract_year_ipc_vs(file)))[:31]  # Joining the list elements to form a single string\n",
    "    df_list.append(final_df)\n",
    "    sheet_names.append(sheet_name)  # Use the joined string as the sheet name\n",
    "\n",
    "# Output all DataFrames to an Excel file\n",
    "output_to_excel(df_list, sheet_names, path +\"/output.xlsx\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

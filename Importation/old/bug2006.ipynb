{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import json\n",
    "import collections\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import tarfile \n",
    "import time\n",
    "\n",
    "year = 2011\n",
    "yearRef = 2006\n",
    "listIPC = [\"G06F\", \"G01N\", \"A61B\", \"B60L\", \"E21B\", \"F03D\", \"H01L\", \"H04W\", \"C07D\", \"D07B\", \"B32B\"]\n",
    "pathData = \"/home/edgarlanoue/data/data\" #\"/home/edgarlanoue/data/data\" # \"C:/Users/edgar/OneDrive/Bureau/Ecole/HEC/A24/BrevetNLP/data\"\n",
    "pathOutput = \"/home/edgarlanoue/data/csv\"  #\"/home/edgarlanoue/data/csv\" #\"C:/Users/edgar/OneDrive/Bureau/Ecole/HEC/A24/BrevetNLP/exemple données\" \n",
    "batch_size= 1\n",
    "\n",
    "pathYear = pathData + f\"/{yearRef}/\"  # Updates with variable year\n",
    "jsonNamesYear = [f for f in listdir(pathYear) if isfile(join(pathYear, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterating through patents of reference year 2006 for evalYear 2011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing patents:   0%|          | 0/29004 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File does not exist or is empty: /home/edgarlanoue/data/data/2006/11558335.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing patents:   0%|          | 0/29004 [00:04<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/tmp/ipykernel_8881/3605729661.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatent_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m                         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Load JSON into d\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m                         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/json/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0mkwarg\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0motherwise\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mJSONDecoder\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mused\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m     \"\"\"\n\u001b[0;32m--> 293\u001b[0;31m     return loads(fp.read(),\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0mcls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject_hook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject_hook\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0mparse_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_float\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_int\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_int\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;31m# decode input (taking the buffer into account)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "year = 2011\n",
    "yearRef = 2006\n",
    "listIPC = [\"G06F\", \"G01N\", \"A61B\", \"B60L\", \"E21B\", \"F03D\", \"H01L\", \"H04W\", \"C07D\", \"D07B\", \"B32B\"]\n",
    "pathData = \"/home/edgarlanoue/data/data\" #\"/home/edgarlanoue/data/data\" # \"C:/Users/edgar/OneDrive/Bureau/Ecole/HEC/A24/BrevetNLP/data\"\n",
    "pathOutput = \"/home/edgarlanoue/data/csv\"  #\"/home/edgarlanoue/data/csv\" #\"C:/Users/edgar/OneDrive/Bureau/Ecole/HEC/A24/BrevetNLP/exemple données\" \n",
    "batch_size= 1000\n",
    "\n",
    "pathYear = pathData + f\"/{yearRef}/\"  # Updates with variable year\n",
    "jsonNamesYear = [f for f in listdir(pathYear) if isfile(join(pathYear, f))]\n",
    "\n",
    "patent_number, titles, backgrounds, claims, summary, abstract, main_ipc, labels, sec_ipc, yearRefVec = {ipc: [] for ipc in listIPC}, {ipc: [] for ipc in listIPC}, {ipc: [] for ipc in listIPC}, {ipc: [] for ipc in listIPC}, {ipc: [] for ipc in listIPC}, {ipc: [] for ipc in listIPC}, {ipc: [] for ipc in listIPC}, {ipc: [] for ipc in listIPC}, {ipc: [] for ipc in listIPC}, {ipc: [] for ipc in listIPC}\n",
    "patent_numberE, titlesE, backgroundsE, claimsE, summaryE, abstractE, main_ipcE, labelsE, sec_ipcE, yearRefVecE = {ipc: [] for ipc in listIPC}, {ipc: [] for ipc in listIPC}, {ipc: [] for ipc in listIPC}, {ipc: [] for ipc in listIPC}, {ipc: [] for ipc in listIPC}, {ipc: [] for ipc in listIPC}, {ipc: [] for ipc in listIPC}, {ipc: [] for ipc in listIPC}, {ipc: [] for ipc in listIPC}, {ipc: [] for ipc in listIPC}\n",
    "\n",
    "current_date = int(f\"{year}0101\")\n",
    "\n",
    "# Create a dictionary to store the expected classes for each IPC\n",
    "expect_classes_ipc_dict = {}\n",
    "\n",
    "# Initialize dictionaries to hold dataframes by IPC and yearRef\n",
    "df_KS_dict = {ipc: {} for ipc in listIPC}\n",
    "df_ES_dict = {ipc: {} for ipc in listIPC}\n",
    "\n",
    "# Load expected classes for each IPC\n",
    "for ipc in listIPC:\n",
    "    expect_classes_ipc_yearRef = []\n",
    "    with open(pathOutput + f'/ES/text/{year}_{ipc}_expectation_IPC_class.txt', 'r') as fp:\n",
    "        for line in fp:\n",
    "            x = line.strip()\n",
    "            expect_classes_ipc_yearRef.append(x)  # Adjust based on your requirements\n",
    "    expect_classes_ipc_dict[ipc] = expect_classes_ipc_yearRef\n",
    "\n",
    "print(f\"Iterating through patents of reference year {yearRef} for evalYear {year}\")\n",
    "\n",
    "total_files = len(jsonNamesYear)\n",
    "\n",
    "# Creates lists for both Knowledge Space (KS) and Expectation Space (ES) with batch-size tqdm\n",
    "with tqdm(total=total_files-280445, desc='Processing patents') as pbar:\n",
    "    for i in range(280445, total_files, batch_size):\n",
    "        for j in range(i, min(i + batch_size, total_files)):  # Process in batches\n",
    "            \n",
    "            patent_path = pathYear + jsonNamesYear[j]\n",
    "            if os.path.exists(patent_path) and os.path.getsize(patent_path) > 0:\n",
    "                with open(patent_path) as f:\n",
    "                    try:\n",
    "                        d = json.load(f)  # Load JSON into d\n",
    "                    except json.JSONDecodeError:\n",
    "                        continue\n",
    "            else:\n",
    "                print(\"File does not exist or is empty:\", patent_path)\n",
    "                # sys.stdout.flush()\n",
    "\n",
    "\n",
    "    # print(d[\"application_number\"], \": \", j)\n",
    "\n",
    "            # with open(patent_path) as f:\n",
    "            #     d = json.load(f)  # Load JSON in d\n",
    "\n",
    "            class_mainIPC = d['main_ipcr_label']\n",
    "            class_main = class_mainIPC[0:4]\n",
    "\n",
    "            # Collect all documents related to the main class for all IPCs\n",
    "            for ipc in listIPC:\n",
    "                # Create Knowledge Space (KS) for this IPC\n",
    "                if class_main == ipc:\n",
    "                    if int(d['date_published']) < current_date or d['decision'] in ['ACCEPTED', 'REJECTED']:\n",
    "                        patent_number[ipc].append(d['application_number'])\n",
    "                        titles[ipc].append(d['title'])\n",
    "                        backgrounds[ipc].append(d['background'])\n",
    "                        claims[ipc].append(d['claims'])\n",
    "                        summary[ipc].append(d['summary'])\n",
    "                        abstract[ipc].append(d['abstract'])\n",
    "                        main_ipc[ipc].append(d['main_ipcr_label'])\n",
    "                        labels[ipc].append(d['decision'])\n",
    "                        sec_ipc[ipc].append(d['ipcr_labels'])\n",
    "                        yearRefVec[ipc].append(yearRef)\n",
    "\n",
    "                # Create Expectation Space (ES) for this IPC\n",
    "                if class_mainIPC in expect_classes_ipc_dict[ipc]:\n",
    "                    if int(d['date_published']) < current_date or d['decision'] in ['ACCEPTED', 'REJECTED']:\n",
    "                        patent_numberE[ipc].append(d['application_number'])\n",
    "                        titlesE[ipc].append(d['title'])\n",
    "                        backgroundsE[ipc].append(d['background'])\n",
    "                        claimsE[ipc].append(d['claims'])\n",
    "                        summaryE[ipc].append(d['summary'])\n",
    "                        abstractE[ipc].append(d['abstract'])\n",
    "                        main_ipcE[ipc].append(d['main_ipcr_label'])\n",
    "                        labelsE[ipc].append(d['decision'])\n",
    "                        sec_ipcE[ipc].append(d['ipcr_labels'])\n",
    "                        yearRefVecE[ipc].append(yearRef)\n",
    "\n",
    "        # Update the progress bar after processing each batch\n",
    "        pbar.update(min(batch_size, total_files - i))\n",
    "\n",
    "for ipc in listIPC:\n",
    "# Store KS dataframe in the nested dictionary\n",
    "    df_KS_dict[ipc][yearRef] = pd.DataFrame({\n",
    "        'application_number': patent_number[ipc],\n",
    "        'title': titles[ipc],\n",
    "        'abstract': abstract[ipc],\n",
    "        'claims': claims[ipc],\n",
    "        'background': backgrounds[ipc],\n",
    "        'summary': summary[ipc],\n",
    "        'ipc': main_ipc[ipc],\n",
    "        'sec_ipc': sec_ipc[ipc],\n",
    "        'label': labels[ipc],\n",
    "        'yearRef': yearRefVec[ipc]\n",
    "    })\n",
    "    # Store ES dataframe in the nested dictionary\n",
    "    df_ES_dict[ipc][yearRef] = pd.DataFrame({\n",
    "        'application_number': patent_numberE[ipc],\n",
    "        'title': titlesE[ipc],\n",
    "        'abstract': abstractE[ipc],\n",
    "        'claims': claimsE[ipc],\n",
    "        'background': backgroundsE[ipc],\n",
    "        'summary': summaryE[ipc],\n",
    "        'ipc': main_ipcE[ipc],\n",
    "        'sec_ipc': sec_ipcE[ipc],\n",
    "        'label': labelsE[ipc],\n",
    "        'yearRef': yearRefVecE[ipc]\n",
    "    })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29001"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "309449 - 280448"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m/var/tmp/ipykernel_8881/339057306.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Read the file content first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Check if the content is valid JSON\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Load JSON in d\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/json/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0mcls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject_hook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject_hook\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0mparse_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_float\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_int\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_int\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m         parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n\u001b[0m\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    346\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 348\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "patent_path = pathYear + jsonNamesYear[280448]\n",
    "with open(patent_path) as f:\n",
    "    content = f.read()  # Read the file content first\n",
    "    print(content)  # Check if the content is valid JSON    \n",
    "    d = json.load(f)  # Load JSON in d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterating through patents of reference year 2006 for evalYear 2011\n",
      "11460891 :  280445\n",
      "10583410 :  280446\n",
      "11531335 :  280447\n",
      "File does not exist or is empty: /home/edgarlanoue/data/data/2006/11558335.json\n",
      "11531335 :  280448\n",
      "11454077 :  280449\n"
     ]
    }
   ],
   "source": [
    "patent_path = pathYear + jsonNamesYear[280448]\n",
    "patent_number, titles, backgrounds, claims, summary, abstract, main_ipc, labels, sec_ipc, yearRefVec = {ipc: [] for ipc in listIPC}, {ipc: [] for ipc in listIPC}, {ipc: [] for ipc in listIPC}, {ipc: [] for ipc in listIPC}, {ipc: [] for ipc in listIPC}, {ipc: [] for ipc in listIPC}, {ipc: [] for ipc in listIPC}, {ipc: [] for ipc in listIPC}, {ipc: [] for ipc in listIPC}, {ipc: [] for ipc in listIPC}\n",
    "patent_numberE, titlesE, backgroundsE, claimsE, summaryE, abstractE, main_ipcE, labelsE, sec_ipcE, yearRefVecE = {ipc: [] for ipc in listIPC}, {ipc: [] for ipc in listIPC}, {ipc: [] for ipc in listIPC}, {ipc: [] for ipc in listIPC}, {ipc: [] for ipc in listIPC}, {ipc: [] for ipc in listIPC}, {ipc: [] for ipc in listIPC}, {ipc: [] for ipc in listIPC}, {ipc: [] for ipc in listIPC}, {ipc: [] for ipc in listIPC}\n",
    "\n",
    "current_date = int(f\"{year}0101\")\n",
    "\n",
    "# Create a dictionary to store the expected classes for each IPC\n",
    "expect_classes_ipc_dict = {}\n",
    "\n",
    "# Initialize dictionaries to hold dataframes by IPC and yearRef\n",
    "df_KS_dict = {ipc: {} for ipc in listIPC}\n",
    "df_ES_dict = {ipc: {} for ipc in listIPC}\n",
    "\n",
    "# Load expected classes for each IPC\n",
    "for ipc in listIPC:\n",
    "    expect_classes_ipc_yearRef = []\n",
    "    with open(pathOutput + f'/ES/text/{year}_{ipc}_expectation_IPC_class.txt', 'r') as fp:\n",
    "        for line in fp:\n",
    "            x = line.strip()\n",
    "            expect_classes_ipc_yearRef.append(x)  # Adjust based on your requirements\n",
    "    expect_classes_ipc_dict[ipc] = expect_classes_ipc_yearRef\n",
    "\n",
    "print(f\"Iterating through patents of reference year {yearRef} for evalYear {year}\")\n",
    "\n",
    "total_files = len(jsonNamesYear)\n",
    "\n",
    "import sys\n",
    "# Creates lists for both Knowledge Space (KS) and Expectation Space (ES) with batch-size tqdm\n",
    "for j in range(280445, 280450):  # Process in batches\n",
    "    patent_path = pathYear + jsonNamesYear[j]\n",
    "    # print(patent_path)\n",
    "    # Check if the file is empty before loading\n",
    "    if os.path.exists(patent_path) and os.path.getsize(patent_path) > 0:\n",
    "        with open(patent_path) as f:\n",
    "            try:\n",
    "                d = json.load(f)  # Load JSON into d\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "    else:\n",
    "        print(\"File does not exist or is empty:\", patent_path)\n",
    "        sys.stdout.flush()\n",
    "\n",
    "\n",
    "    print(d[\"application_number\"], \": \", j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File does not exist or is empty: /home/edgarlanoue/data/data/2006/11558335.json\n"
     ]
    }
   ],
   "source": [
    "for j in range(280445, 280450):  # Process in batches\n",
    "    patent_path = pathYear + jsonNamesYear[j]\n",
    "    # Check if the file exists and is not empty\n",
    "    if os.path.exists(patent_path) and os.path.getsize(patent_path) > 0:\n",
    "        with open(patent_path) as f:\n",
    "            try:\n",
    "                d = json.load(f)  # Load JSON into d\n",
    "            except json.JSONDecodeError:\n",
    "                print(\"Error: Invalid JSON file -\", patent_path)\n",
    "                sys.stdout.flush()\n",
    "            except Exception as e:\n",
    "                print(\"Unexpected error:\", e)\n",
    "                sys.stdout.flush()\n",
    "            \n",
    "            # If `d` is empty (like `{}`), skip to the next iteration\n",
    "            if not d:\n",
    "                print(\"Error: Empty JSON file -\", patent_path)\n",
    "                sys.stdout.flush()\n",
    "    else:\n",
    "        print(\"File does not exist or is empty:\", patent_path)\n",
    "        sys.stdout.flush()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import json\n",
    "import collections\n",
    "import re\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function returning T if years are valid and present in dataset\n",
    "def checkYears(year, yearsNeeded, pathData):\n",
    "    ret = False\n",
    "    folder_names = [folder for folder in os.listdir(pathData) if os.path.isdir(os.path.join(pathData, folder))]\n",
    "    folder_years = [int(name) for name in folder_names] \n",
    "    required_years = set(range(year - yearsNeeded, year))\n",
    "    missing_years = required_years - set(folder_years)\n",
    "\n",
    "    # Check for missing 2004 and 2005\n",
    "    if {2004}.issubset(required_years | {year}) or {2005}.issubset(required_years | {year}):\n",
    "        print(\"Missing IPC\")\n",
    "    if {2017}.issubset(required_years | {year}) or {2018}.issubset(required_years | {year}):\n",
    "        print(\"Incomplete data\")\n",
    "\n",
    "    # General check for missing years\n",
    "    if not missing_years:\n",
    "        print(\"All years present\")\n",
    "    else:\n",
    "        print(f\"Missing years: {missing_years}\")\n",
    "    if not missing_years and not({2004}.issubset(required_years | {year}) or {2005}.issubset(required_years | {year})) and not({2017}.issubset(required_years | {year}) or {2018}.issubset(required_years | {year})):\n",
    "        ret = True                                                                                                                      \n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function taking year, IPC class, path to data, and path to output and writing CSV file toEval for current year and IPC, and also writing secondary IPC in /text/_.txt\n",
    "# Needs a directory /test in output path\n",
    "def json2toEval(year, ipc, pathData, pathOutput):\n",
    "    pathYear = pathData+ f\"/{year}/\"                                # Updates with variable year\n",
    "    jsonNamesYear = [f for f in listdir(pathYear) if isfile(join(pathYear, f))] \n",
    "\n",
    "    # Initialization of list for IPC class\n",
    "    decision_ipc  = collections.defaultdict(int) # Initialization of dict for IPC class - initialized at 0, used to count occurences   \n",
    "    patent_ipc_list = [] # initialization of list for IPC class \n",
    "\n",
    "    # Creates list of patents from this IPC class\n",
    "    for i in tqdm(range(len(jsonNamesYear))):\n",
    "        patent_path = pathYear + jsonNamesYear[i]\n",
    "        with open(patent_path) as f:\n",
    "            d = json.load(f) # load json in d\n",
    "            f.close()   # close f - not needed with \"with ___ as\" syntax\n",
    "        class_mainIPC = d['main_ipcr_label']\n",
    "        if re.match(f'^{ipc}', class_mainIPC):\n",
    "            patent_ipc_list.append(jsonNamesYear[i])\n",
    "            decision_ipc[d['decision']] += 1\n",
    "\n",
    "    # Create list exluding all other than accepted and rejected\n",
    "    final_patents = []\n",
    "    for i in tqdm(range(len(patent_ipc_list))):\n",
    "        patent_path = pathYear + patent_ipc_list[i]\n",
    "        with open(patent_path) as f:\n",
    "            d = json.load(f)\n",
    "            f.close()\n",
    "        if d['decision'] == 'ACCEPTED' or d['decision'] == 'REJECTED': # exclude all other\n",
    "            final_patents.append(patent_ipc_list[i])\n",
    "\n",
    "    # Load needed data for patents\n",
    "    non_main_ipc = []\n",
    "    labels, patent_number, titles, backgrounds, claims, summary, abstract, main_ipc, sec_ipc = [], [], [], [], [], [], [], [], []\n",
    "\n",
    "    for i in tqdm(range(len(final_patents))):\n",
    "        patent_path = pathYear + final_patents[i]\n",
    "        with open(patent_path) as f:\n",
    "            d = json.load(f)\n",
    "            f.close() # ligne inutile\n",
    "        \n",
    "        #Creating the lists for the other information\n",
    "        patent_number.append(d['application_number'])\n",
    "        titles.append(d['title'])\n",
    "        backgrounds.append(d['background'])\n",
    "        claims.append(d['claims'])\n",
    "        summary.append(d['summary'])\n",
    "        abstract.append(d['abstract'])\n",
    "        main_ipc.append(d['main_ipcr_label'])\n",
    "        sec_ipc.append(d['ipcr_labels'])\n",
    "\n",
    "        #Collecting non main ipc class -useful to create good expectation class\n",
    "        non_main =  d['ipcr_labels']\n",
    "        for ipcr in non_main:\n",
    "            non_main_ipc.append(ipcr) # only 4 first characters to be sure of being at same level\n",
    "        #Getting labels based on decision\n",
    "        label = 0\n",
    "        if d['decision'] == 'ACCEPTED':\n",
    "            label = 1\n",
    "        labels.append(label)\n",
    "\n",
    "    # Keep only secondary class that are not the main ipc class\n",
    "    expectations_classes = list(set(non_main_ipc)) # unique secondary ipc classes\n",
    "    good_expectations_classes = []\n",
    "    for ipcr in expectations_classes:\n",
    "        if ipcr[0:4] != f\"{ipc}\":\n",
    "            good_expectations_classes.append(ipcr)\n",
    "\n",
    "    # df to csv\n",
    "    df = pd.DataFrame({'application_number': patent_number, 'title': titles, 'abstract':abstract,\n",
    "                        'claims':claims, 'background': backgrounds, 'summary':summary, 'ipc':ipc, 'sec_ipc': sec_ipc, 'label': labels})\n",
    "\n",
    "    df.to_csv(pathOutput + f'/toEval/{year}_{ipc}_patents_toEval.csv', index=False)\n",
    "    print(\"CSV done\")\n",
    "    # Save IPC in text format\n",
    "    with open(pathOutput + f'/ES/text/{year}_{ipc}_expectation_IPC_class.txt', 'w') as fp:\n",
    "        for item in good_expectations_classes:\n",
    "            # write each item on a new line\n",
    "            fp.write(\"%s\\n\" % item)\n",
    "        print('.txt Done')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 2631.70it/s]\n",
      "100%|██████████| 121/121 [00:00<00:00, 2559.18it/s]\n",
      "100%|██████████| 117/117 [00:00<00:00, 3087.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV done\n",
      ".txt Done\n"
     ]
    }
   ],
   "source": [
    "pathData = \"C:/Users/edgar/OneDrive/Bureau/Ecole/HEC/A24/BrevetNLP/data\"\n",
    "pathOutput = \"C:/Users/edgar/OneDrive/Bureau/Ecole/HEC/A24/BrevetNLP/exemple données\"\n",
    "json2toEval(2011, \"H01L\", pathData, pathOutput)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
